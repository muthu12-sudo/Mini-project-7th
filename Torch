import torch
import cv2
import numpy as np
import streamlit as st
from torchvision import transforms
from PIL import Image
from collections import OrderedDict

# Streamlit app title and description
st.title("Custom Model Inference App")
st.write("Upload an image or video to run inference using your custom PyTorch model.")

# Function to load a custom model
@st.cache_resource
def load_custom_model(model_path, num_classes):
    """
    Loads a custom PyTorch model for inference.
    """
    class CustomModel(torch.nn.Module):
        def __init__(self, num_classes):
            super(CustomModel, self).__init__()
            from torchvision.models import resnet101  # Replace with your backbone
            self.base_model = resnet101(pretrained=False)
            self.base_model.fc = torch.nn.Linear(2048, num_classes)

        def forward(self, x):
            return self.base_model(x)

    model = CustomModel(num_classes=num_classes)
    state_dict = torch.load(model_path, map_location=torch.device("cpu"))

    # Fix keys if necessary
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        name = k.replace("module.", "")  # Remove 'module.' prefix if present
        new_state_dict[name] = v

    model.load_state_dict(new_state_dict, strict=False)
    model.eval()  # Set to evaluation mode
    return model


# Initialize model
MODEL_PATH = "model.pth"  # Path to your .pth model
NUM_CLASSES = 2  # Number of output classes (update accordingly)
model = load_custom_model(MODEL_PATH, NUM_CLASSES)
st.success("Model loaded successfully!")


# Function to preprocess image
def preprocess_image(image):
    """
    Preprocesses an image for model inference.
    """
    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # Resize to match input size
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return transform(image).unsqueeze(0)  # Add batch dimension


# Function to predict on an image
def predict_image(image, model):
    """
    Runs inference on a single image.
    """
    input_tensor = preprocess_image(image)
    with torch.no_grad():
        outputs = model(input_tensor)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
    return probabilities


# Upload and process an image
uploaded_image = st.file_uploader("Upload an image (jpg/png)", type=["jpg", "png"])
if uploaded_image:
    image = Image.open(uploaded_image).convert("RGB")
    st.image(image, caption="Uploaded Image", use_column_width=True)

    # Run inference
    st.write("Running inference...")
    probabilities = predict_image(image, model)
    st.write("Predictions (class probabilities):", probabilities.numpy())

# Upload and process a video
uploaded_video = st.file_uploader("Upload a video (mp4/avi)", type=["mp4", "avi"])
if uploaded_video:
    # Save uploaded video to a temporary path
    temp_video_path = "temp_video.mp4"
    with open(temp_video_path, "wb") as f:
        f.write(uploaded_video.read())

    st.video(temp_video_path)
    st.write("Running video inference...")

    # Open video with OpenCV
    cap = cv2.VideoCapture(temp_video_path)
    frame_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Process frame
        frame_count += 1
        frame_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        probabilities = predict_image(frame_image, model)

        # Display inference results
        st.write(f"Frame {frame_count}: Predictions (class probabilities):", probabilities.numpy())

    cap.release()
    st.success("Video inference completed!")

# Conclusion
st.write("This app uses your custom PyTorch model for inference on images and videos.")
